/scratch/wangtiantong/miniconda3/envs/task-vectors/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
2025-01-25 15:13:34,043 - INFO - Starting m_TIES script.
2025-01-25 15:13:34,044 - INFO - Building an unlabeled combined DataLoader.
2025-01-25 15:13:34,044 - INFO - Loading dataset 'MNIST' for unlabeled sampling.
2025-01-25 15:13:34,111 - INFO - Dataset 'MNIST': Chosen 500 samples out of 60000.
2025-01-25 15:13:34,111 - INFO - Loading dataset 'DTD' for unlabeled sampling.
2025-01-25 15:13:34,121 - INFO - Dataset 'DTD': Chosen 18 samples out of 1880.
2025-01-25 15:13:34,122 - INFO - Loading dataset 'EuroSAT' for unlabeled sampling.
2025-01-25 15:13:34,161 - INFO - Dataset 'EuroSAT': Chosen 216 samples out of 21600.
2025-01-25 15:13:34,161 - INFO - Loading dataset 'GTSRB' for unlabeled sampling.
2025-01-25 15:13:34,245 - INFO - Dataset 'GTSRB': Chosen 266 samples out of 26640.
2025-01-25 15:13:34,245 - INFO - Loading dataset 'SUN397' for unlabeled sampling.
2025-01-25 15:13:34,921 - INFO - Dataset 'SUN397': Chosen 500 samples out of 87003.
2025-01-25 15:13:34,921 - INFO - Loading dataset 'SVHN' for unlabeled sampling.
2025-01-25 15:13:37,673 - INFO - Dataset 'SVHN': Chosen 500 samples out of 73257.
2025-01-25 15:13:37,673 - INFO - Total combined unlabeled samples: 2000
2025-01-25 15:13:37,673 - INFO - Unlabeled DataLoader created successfully.
2025-01-25 15:13:37,676 - INFO - Unlabeled data loader built successfully.
2025-01-25 15:13:37,676 - INFO - Performing m_ties_merging with row-wise robust scaling on specified layers.
2025-01-25 15:13:37,676 - INFO - Starting m_TIES merging process.
2025-01-25 15:13:37,676 - INFO - Using base keep ratio k=0.2 and vibration coefficient e=0.19.
2025-01-25 15:13:37,676 - INFO - Loading pretrained model from 'checkpoints/ViT-B-32/zeroshot.pt'.
/scratch/wangtiantong/task_vectors/m_ties.py:132: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  pretrained_model = torch.load(pretrained_checkpoint, map_location='cpu')
2025-01-25 15:13:37,951 - INFO - Pretrained model loaded. Creating parameter keys list.
2025-01-25 15:13:37,951 - INFO - Loading finetuned checkpoint 'checkpoints/ViT-B-32/MNIST/finetuned.pt'.
/scratch/wangtiantong/task_vectors/src/task_vectors.py:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  pretrained_state_dict = torch.load(pretrained_checkpoint).state_dict()
/scratch/wangtiantong/task_vectors/src/task_vectors.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  finetuned_state_dict = torch.load(finetuned_checkpoint).state_dict()
2025-01-25 15:13:38,506 - INFO - Created task vector from 'checkpoints/ViT-B-32/MNIST/finetuned.pt' (finetuned - pretrained).
2025-01-25 15:13:38,507 - INFO - Loading finetuned checkpoint 'checkpoints/ViT-B-32/DTD/finetuned.pt'.
2025-01-25 15:13:38,973 - INFO - Created task vector from 'checkpoints/ViT-B-32/DTD/finetuned.pt' (finetuned - pretrained).
2025-01-25 15:13:38,974 - INFO - Loading finetuned checkpoint 'checkpoints/ViT-B-32/EuroSAT/finetuned.pt'.
2025-01-25 15:13:39,300 - INFO - Created task vector from 'checkpoints/ViT-B-32/EuroSAT/finetuned.pt' (finetuned - pretrained).
2025-01-25 15:13:39,300 - INFO - Loading finetuned checkpoint 'checkpoints/ViT-B-32/GTSRB/finetuned.pt'.
2025-01-25 15:13:39,586 - INFO - Created task vector from 'checkpoints/ViT-B-32/GTSRB/finetuned.pt' (finetuned - pretrained).
2025-01-25 15:13:39,587 - INFO - Loading finetuned checkpoint 'checkpoints/ViT-B-32/SUN397/finetuned.pt'.
2025-01-25 15:13:39,876 - INFO - Created task vector from 'checkpoints/ViT-B-32/SUN397/finetuned.pt' (finetuned - pretrained).
2025-01-25 15:13:39,876 - INFO - Loading finetuned checkpoint 'checkpoints/ViT-B-32/SVHN/finetuned.pt'.
2025-01-25 15:13:40,168 - INFO - Created task vector from 'checkpoints/ViT-B-32/SVHN/finetuned.pt' (finetuned - pretrained).
2025-01-25 15:13:52,009 - INFO - m_TIES merging process completed.
2025-01-25 15:13:52,080 - INFO - Applying merged task vectors to the pretrained model.
/scratch/wangtiantong/task_vectors/src/task_vectors.py:58: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  pretrained_model = torch.load(pretrained_checkpoint)
2025-01-25 15:13:52,553 - INFO - Merged model constructed successfully.
2025-01-25 15:13:52,553 - INFO - Evaluating merged model on each dataset.
2025-01-25 15:13:52,553 - INFO - Evaluating dataset 'MNIST'.
/scratch/wangtiantong/task_vectors/src/utils.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model = torch.load(save_path)
Using downloaded and verified file: datasets/svhn/train_32x32.mat
Using downloaded and verified file: datasets/svhn/test_32x32.mat
Classification head for ViT-B-32 on MNIST exists at checkpoints/ViT-B-32/head_MNIST.pt
Loading classification head from checkpoints/ViT-B-32/head_MNIST.pt
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:01<01:43,  1.33s/it]  4%|▍         | 3/79 [00:01<00:29,  2.56it/s]  6%|▋         | 5/79 [00:01<00:16,  4.44it/s]  9%|▉         | 7/79 [00:01<00:11,  6.33it/s] 11%|█▏        | 9/79 [00:01<00:08,  8.12it/s] 14%|█▍        | 11/79 [00:01<00:07,  9.65it/s] 16%|█▋        | 13/79 [00:02<00:06, 10.33it/s] 19%|█▉        | 15/79 [00:02<00:05, 11.39it/s] 22%|██▏       | 17/79 [00:02<00:05, 10.69it/s] 24%|██▍       | 19/79 [00:02<00:06,  9.44it/s] 27%|██▋       | 21/79 [00:03<00:06,  8.58it/s] 28%|██▊       | 22/79 [00:03<00:06,  8.53it/s] 29%|██▉       | 23/79 [00:03<00:06,  8.40it/s] 30%|███       | 24/79 [00:03<00:06,  8.15it/s] 32%|███▏      | 25/79 [00:03<00:06,  8.08it/s] 33%|███▎      | 26/79 [00:03<00:06,  7.88it/s] 34%|███▍      | 27/79 [00:03<00:06,  7.97it/s] 35%|███▌      | 28/79 [00:03<00:06,  8.00it/s] 37%|███▋      | 29/79 [00:04<00:06,  8.03it/s] 38%|███▊      | 30/79 [00:04<00:06,  8.01it/s] 39%|███▉      | 31/79 [00:04<00:05,  8.15it/s] 42%|████▏     | 33/79 [00:04<00:04, 10.00it/s] 44%|████▍     | 35/79 [00:04<00:03, 11.48it/s] 47%|████▋     | 37/79 [00:04<00:03, 12.68it/s] 49%|████▉     | 39/79 [00:04<00:03, 13.28it/s] 52%|█████▏    | 41/79 [00:04<00:02, 13.81it/s] 54%|█████▍    | 43/79 [00:05<00:02, 14.27it/s] 57%|█████▋    | 45/79 [00:05<00:02, 14.29it/s] 59%|█████▉    | 47/79 [00:05<00:02, 14.53it/s] 62%|██████▏   | 49/79 [00:05<00:02, 14.46it/s] 65%|██████▍   | 51/79 [00:05<00:01, 14.62it/s] 67%|██████▋   | 53/79 [00:05<00:01, 14.82it/s] 70%|██████▉   | 55/79 [00:05<00:01, 14.81it/s] 72%|███████▏  | 57/79 [00:06<00:01, 15.01it/s] 75%|███████▍  | 59/79 [00:06<00:01, 15.04it/s] 77%|███████▋  | 61/79 [00:06<00:01, 14.79it/s] 80%|███████▉  | 63/79 [00:06<00:01, 14.94it/s] 82%|████████▏ | 65/79 [00:06<00:00, 14.84it/s] 85%|████████▍ | 67/79 [00:06<00:00, 14.86it/s] 87%|████████▋ | 69/79 [00:06<00:00, 15.00it/s] 90%|████████▉ | 71/79 [00:07<00:00, 14.88it/s] 92%|█████████▏| 73/79 [00:07<00:00, 14.94it/s] 95%|█████████▍| 75/79 [00:07<00:00, 15.02it/s] 97%|█████████▋| 77/79 [00:07<00:00, 15.03it/s]100%|██████████| 79/79 [00:07<00:00, 10.38it/s]
2025-01-25 15:14:00,227 - INFO - Results for 'MNIST': {'top1': 0.9882}
2025-01-25 15:14:00,227 - INFO - Evaluating dataset 'DTD'.
Done evaluating on MNIST. Accuracy: 98.82%
Classification head for ViT-B-32 on DTD exists at checkpoints/ViT-B-32/head_DTD.pt
Loading classification head from checkpoints/ViT-B-32/head_DTD.pt
  0%|          | 0/15 [00:00<?, ?it/s]  7%|▋         | 1/15 [00:01<00:17,  1.24s/it] 20%|██        | 3/15 [00:01<00:04,  2.71it/s] 33%|███▎      | 5/15 [00:01<00:02,  4.70it/s] 47%|████▋     | 7/15 [00:01<00:01,  6.63it/s] 60%|██████    | 9/15 [00:01<00:00,  8.40it/s] 73%|███████▎  | 11/15 [00:01<00:00, 10.00it/s] 87%|████████▋ | 13/15 [00:02<00:00, 10.62it/s]100%|██████████| 15/15 [00:02<00:00, 12.01it/s]100%|██████████| 15/15 [00:02<00:00,  6.63it/s]
2025-01-25 15:14:02,511 - INFO - Results for 'DTD': {'top1': 0.5792553191489361}
2025-01-25 15:14:02,511 - INFO - Evaluating dataset 'EuroSAT'.
Done evaluating on DTD. Accuracy: 57.93%
Classification head for ViT-B-32 on EuroSAT exists at checkpoints/ViT-B-32/head_EuroSAT.pt
Loading classification head from checkpoints/ViT-B-32/head_EuroSAT.pt
  0%|          | 0/43 [00:00<?, ?it/s]  2%|▏         | 1/43 [00:00<00:36,  1.14it/s]  7%|▋         | 3/43 [00:01<00:11,  3.59it/s] 12%|█▏        | 5/43 [00:01<00:06,  5.85it/s] 16%|█▋        | 7/43 [00:01<00:04,  7.91it/s] 21%|██        | 9/43 [00:01<00:03,  8.68it/s] 26%|██▌       | 11/43 [00:01<00:04,  7.99it/s] 30%|███       | 13/43 [00:02<00:03,  7.66it/s] 33%|███▎      | 14/43 [00:02<00:03,  7.76it/s] 35%|███▍      | 15/43 [00:02<00:03,  7.87it/s] 37%|███▋      | 16/43 [00:02<00:03,  7.72it/s] 40%|███▉      | 17/43 [00:02<00:03,  7.55it/s] 42%|████▏     | 18/43 [00:02<00:03,  7.44it/s] 44%|████▍     | 19/43 [00:02<00:03,  7.61it/s] 47%|████▋     | 20/43 [00:02<00:02,  7.69it/s] 49%|████▉     | 21/43 [00:03<00:02,  7.82it/s] 51%|█████     | 22/43 [00:03<00:02,  7.92it/s] 53%|█████▎    | 23/43 [00:03<00:02,  8.22it/s] 58%|█████▊    | 25/43 [00:03<00:01,  9.95it/s] 63%|██████▎   | 27/43 [00:03<00:01, 11.32it/s] 67%|██████▋   | 29/43 [00:03<00:01, 12.34it/s] 72%|███████▏  | 31/43 [00:03<00:00, 12.89it/s] 77%|███████▋  | 33/43 [00:04<00:00, 13.33it/s] 81%|████████▏ | 35/43 [00:04<00:00, 13.82it/s] 86%|████████▌ | 37/43 [00:04<00:00, 14.04it/s] 91%|█████████ | 39/43 [00:04<00:00, 14.11it/s] 95%|█████████▌| 41/43 [00:04<00:00, 14.38it/s]100%|██████████| 43/43 [00:04<00:00,  9.03it/s]
2025-01-25 15:14:07,329 - INFO - Results for 'EuroSAT': {'top1': 0.7633333333333333}
2025-01-25 15:14:07,329 - INFO - Evaluating dataset 'GTSRB'.
Done evaluating on EuroSAT. Accuracy: 76.33%
Classification head for ViT-B-32 on GTSRB exists at checkpoints/ViT-B-32/head_GTSRB.pt
Loading classification head from checkpoints/ViT-B-32/head_GTSRB.pt
  0%|          | 0/99 [00:00<?, ?it/s]  1%|          | 1/99 [00:00<01:22,  1.19it/s]  3%|▎         | 3/99 [00:00<00:26,  3.64it/s]  5%|▌         | 5/99 [00:01<00:15,  5.97it/s]  7%|▋         | 7/99 [00:01<00:11,  7.94it/s]  9%|▉         | 9/99 [00:01<00:09,  9.68it/s] 11%|█         | 11/99 [00:01<00:08, 10.98it/s] 13%|█▎        | 13/99 [00:01<00:07, 11.93it/s] 15%|█▌        | 15/99 [00:01<00:06, 12.85it/s] 17%|█▋        | 17/99 [00:01<00:06, 13.49it/s] 19%|█▉        | 19/99 [00:02<00:05, 13.45it/s] 21%|██        | 21/99 [00:02<00:05, 13.79it/s] 23%|██▎       | 23/99 [00:02<00:05, 14.08it/s] 25%|██▌       | 25/99 [00:02<00:05, 14.24it/s] 27%|██▋       | 27/99 [00:02<00:04, 14.45it/s] 29%|██▉       | 29/99 [00:02<00:04, 14.43it/s] 31%|███▏      | 31/99 [00:02<00:04, 14.48it/s] 33%|███▎      | 33/99 [00:03<00:04, 14.62it/s] 35%|███▌      | 35/99 [00:03<00:04, 14.22it/s] 37%|███▋      | 37/99 [00:03<00:04, 14.34it/s] 39%|███▉      | 39/99 [00:03<00:04, 14.53it/s] 41%|████▏     | 41/99 [00:03<00:04, 14.49it/s] 43%|████▎     | 43/99 [00:03<00:03, 14.53it/s] 45%|████▌     | 45/99 [00:03<00:03, 14.46it/s] 47%|████▋     | 47/99 [00:04<00:03, 14.63it/s] 49%|████▉     | 49/99 [00:04<00:03, 14.74it/s] 52%|█████▏    | 51/99 [00:04<00:03, 14.45it/s] 54%|█████▎    | 53/99 [00:04<00:03, 12.78it/s] 56%|█████▌    | 55/99 [00:04<00:04, 10.24it/s] 58%|█████▊    | 57/99 [00:05<00:04,  8.86it/s] 59%|█████▊    | 58/99 [00:05<00:04,  8.61it/s] 60%|█████▉    | 59/99 [00:05<00:04,  8.41it/s] 61%|██████    | 60/99 [00:05<00:04,  8.01it/s] 62%|██████▏   | 61/99 [00:05<00:04,  7.77it/s] 63%|██████▎   | 62/99 [00:05<00:04,  7.62it/s] 64%|██████▎   | 63/99 [00:05<00:04,  7.71it/s] 65%|██████▍   | 64/99 [00:06<00:04,  7.78it/s] 66%|██████▌   | 65/99 [00:06<00:04,  7.88it/s] 67%|██████▋   | 66/99 [00:06<00:04,  7.88it/s] 69%|██████▊   | 68/99 [00:06<00:03,  9.44it/s] 71%|███████   | 70/99 [00:06<00:02, 11.05it/s] 73%|███████▎  | 72/99 [00:06<00:02, 12.23it/s] 75%|███████▍  | 74/99 [00:06<00:01, 12.79it/s] 77%|███████▋  | 76/99 [00:06<00:01, 13.26it/s] 79%|███████▉  | 78/99 [00:07<00:01, 13.52it/s] 81%|████████  | 80/99 [00:07<00:01, 13.97it/s] 83%|████████▎ | 82/99 [00:07<00:01, 14.20it/s] 85%|████████▍ | 84/99 [00:07<00:01, 14.26it/s] 87%|████████▋ | 86/99 [00:07<00:00, 14.54it/s] 89%|████████▉ | 88/99 [00:07<00:00, 14.53it/s] 91%|█████████ | 90/99 [00:07<00:00, 14.34it/s] 93%|█████████▎| 92/99 [00:08<00:00, 14.38it/s] 95%|█████████▍| 94/99 [00:08<00:00, 14.31it/s] 97%|█████████▋| 96/99 [00:08<00:00, 14.47it/s] 99%|█████████▉| 98/99 [00:08<00:00, 14.48it/s]100%|██████████| 99/99 [00:08<00:00, 11.49it/s]
2025-01-25 15:14:16,035 - INFO - Results for 'GTSRB': {'top1': 0.7705463182897863}
2025-01-25 15:14:16,035 - INFO - Evaluating dataset 'SUN397'.
Done evaluating on GTSRB. Accuracy: 77.05%
Classification head for ViT-B-32 on SUN397 exists at checkpoints/ViT-B-32/head_SUN397.pt
Loading classification head from checkpoints/ViT-B-32/head_SUN397.pt
  0%|          | 0/170 [00:00<?, ?it/s]  1%|          | 1/170 [00:03<09:58,  3.54s/it]  1%|          | 2/170 [00:03<04:17,  1.53s/it]  2%|▏         | 3/170 [00:03<02:29,  1.12it/s]  2%|▏         | 4/170 [00:03<01:40,  1.66it/s]  3%|▎         | 5/170 [00:04<01:11,  2.31it/s]  4%|▎         | 6/170 [00:04<00:53,  3.04it/s]  4%|▍         | 7/170 [00:04<00:42,  3.82it/s]  5%|▍         | 8/170 [00:04<00:35,  4.58it/s]  5%|▌         | 9/170 [00:04<00:30,  5.31it/s]  6%|▋         | 11/170 [00:04<00:21,  7.36it/s]  8%|▊         | 13/170 [00:04<00:17,  9.21it/s]  9%|▉         | 15/170 [00:05<00:14, 10.45it/s] 10%|█         | 17/170 [00:05<00:30,  5.05it/s] 11%|█         | 19/170 [00:05<00:23,  6.39it/s] 12%|█▏        | 21/170 [00:06<00:19,  7.78it/s] 14%|█▎        | 23/170 [00:06<00:16,  9.14it/s] 15%|█▍        | 25/170 [00:06<00:14, 10.16it/s] 16%|█▌        | 27/170 [00:06<00:12, 11.24it/s] 17%|█▋        | 29/170 [00:06<00:11, 12.11it/s] 18%|█▊        | 31/170 [00:06<00:11, 12.57it/s] 19%|█▉        | 33/170 [00:07<00:31,  4.37it/s] 21%|██        | 35/170 [00:08<00:24,  5.52it/s] 22%|██▏       | 37/170 [00:08<00:19,  6.78it/s] 23%|██▎       | 39/170 [00:08<00:16,  8.07it/s] 24%|██▍       | 41/170 [00:08<00:13,  9.36it/s] 25%|██▌       | 43/170 [00:08<00:12, 10.45it/s] 26%|██▋       | 45/170 [00:08<00:10, 11.37it/s] 28%|██▊       | 47/170 [00:08<00:10, 12.06it/s] 29%|██▉       | 49/170 [00:10<00:28,  4.17it/s] 30%|███       | 51/170 [00:10<00:24,  4.79it/s] 31%|███       | 52/170 [00:10<00:23,  5.05it/s] 31%|███       | 53/170 [00:10<00:21,  5.39it/s] 32%|███▏      | 54/170 [00:10<00:19,  5.83it/s] 32%|███▏      | 55/170 [00:10<00:18,  6.18it/s] 33%|███▎      | 56/170 [00:11<00:17,  6.52it/s] 34%|███▎      | 57/170 [00:11<00:16,  6.81it/s] 35%|███▍      | 59/170 [00:11<00:13,  8.43it/s] 36%|███▌      | 61/170 [00:11<00:11,  9.88it/s] 37%|███▋      | 63/170 [00:11<00:09, 11.08it/s] 38%|███▊      | 65/170 [00:12<00:16,  6.24it/s] 39%|███▉      | 67/170 [00:12<00:13,  7.59it/s] 41%|████      | 69/170 [00:12<00:11,  8.91it/s] 42%|████▏     | 71/170 [00:12<00:09,  9.99it/s] 43%|████▎     | 73/170 [00:12<00:08, 10.88it/s] 44%|████▍     | 75/170 [00:12<00:08, 11.70it/s] 45%|████▌     | 77/170 [00:13<00:07, 12.29it/s] 46%|████▋     | 79/170 [00:13<00:07, 12.75it/s] 48%|████▊     | 81/170 [00:14<00:16,  5.49it/s] 49%|████▉     | 83/170 [00:14<00:12,  6.78it/s] 50%|█████     | 85/170 [00:14<00:10,  8.12it/s] 51%|█████     | 87/170 [00:15<00:19,  4.28it/s] 52%|█████▏    | 89/170 [00:15<00:14,  5.45it/s] 54%|█████▎    | 91/170 [00:15<00:11,  6.67it/s] 55%|█████▍    | 93/170 [00:15<00:09,  7.97it/s] 56%|█████▌    | 95/170 [00:15<00:08,  9.20it/s] 57%|█████▋    | 97/170 [00:16<00:07, 10.17it/s] 58%|█████▊    | 99/170 [00:16<00:11,  5.95it/s] 59%|█████▉    | 101/170 [00:16<00:09,  7.25it/s] 61%|██████    | 103/170 [00:17<00:11,  5.71it/s] 62%|██████▏   | 105/170 [00:17<00:09,  6.96it/s] 63%|██████▎   | 107/170 [00:17<00:07,  8.16it/s] 64%|██████▍   | 109/170 [00:17<00:06,  9.32it/s] 65%|██████▌   | 111/170 [00:17<00:05, 10.15it/s] 66%|██████▋   | 113/170 [00:18<00:06,  9.10it/s] 68%|██████▊   | 115/170 [00:19<00:11,  4.99it/s] 68%|██████▊   | 116/170 [00:19<00:10,  5.35it/s] 69%|██████▉   | 117/170 [00:19<00:09,  5.70it/s] 69%|██████▉   | 118/170 [00:19<00:08,  6.13it/s] 70%|███████   | 119/170 [00:19<00:08,  5.84it/s] 71%|███████   | 121/170 [00:19<00:06,  7.75it/s] 72%|███████▏  | 123/170 [00:19<00:05,  9.31it/s] 74%|███████▎  | 125/170 [00:20<00:04, 10.46it/s] 75%|███████▍  | 127/170 [00:20<00:03, 11.55it/s] 76%|███████▌  | 129/170 [00:20<00:03, 12.31it/s] 77%|███████▋  | 131/170 [00:22<00:12,  3.04it/s] 78%|███████▊  | 133/170 [00:22<00:09,  4.04it/s] 79%|███████▉  | 135/170 [00:22<00:09,  3.56it/s] 81%|████████  | 137/170 [00:23<00:07,  4.63it/s] 82%|████████▏ | 139/170 [00:23<00:05,  5.85it/s] 83%|████████▎ | 141/170 [00:23<00:04,  7.14it/s] 84%|████████▍ | 143/170 [00:23<00:03,  8.34it/s] 85%|████████▌ | 145/170 [00:23<00:02,  9.53it/s] 86%|████████▋ | 147/170 [00:23<00:02,  7.77it/s] 88%|████████▊ | 149/170 [00:24<00:02,  9.04it/s] 89%|████████▉ | 151/170 [00:25<00:04,  3.85it/s] 90%|█████████ | 153/170 [00:25<00:03,  4.94it/s] 91%|█████████ | 155/170 [00:25<00:02,  6.10it/s] 92%|█████████▏| 157/170 [00:25<00:01,  7.40it/s] 94%|█████████▎| 159/170 [00:25<00:01,  8.65it/s] 95%|█████████▍| 161/170 [00:26<00:00,  9.81it/s] 96%|█████████▌| 163/170 [00:26<00:00,  9.74it/s] 97%|█████████▋| 165/170 [00:26<00:00, 10.68it/s] 98%|█████████▊| 167/170 [00:27<00:00,  4.76it/s] 99%|█████████▉| 168/170 [00:27<00:00,  5.13it/s] 99%|█████████▉| 169/170 [00:27<00:00,  5.54it/s]100%|██████████| 170/170 [00:27<00:00,  6.01it/s]100%|██████████| 170/170 [00:27<00:00,  6.11it/s]
2025-01-25 15:14:44,600 - INFO - Results for 'SUN397': {'top1': 0.6142706082478967}
2025-01-25 15:14:44,600 - INFO - Evaluating dataset 'SVHN'.
Done evaluating on SUN397. Accuracy: 61.43%
Classification head for ViT-B-32 on SVHN exists at checkpoints/ViT-B-32/head_SVHN.pt
Loading classification head from checkpoints/ViT-B-32/head_SVHN.pt
Using downloaded and verified file: datasets/svhn/train_32x32.mat
Using downloaded and verified file: datasets/svhn/test_32x32.mat
  0%|          | 0/204 [00:00<?, ?it/s]  0%|          | 1/204 [00:00<03:01,  1.12it/s]  1%|▏         | 3/204 [00:01<00:57,  3.51it/s]  2%|▏         | 5/204 [00:01<00:34,  5.78it/s]  3%|▎         | 7/204 [00:01<00:25,  7.81it/s]  4%|▍         | 9/204 [00:01<00:20,  9.56it/s]  5%|▌         | 11/204 [00:01<00:17, 10.92it/s]  6%|▋         | 13/204 [00:01<00:15, 12.02it/s]  7%|▋         | 15/204 [00:01<00:14, 12.88it/s]  8%|▊         | 17/204 [00:01<00:14, 13.22it/s]  9%|▉         | 19/204 [00:02<00:13, 13.43it/s] 10%|█         | 21/204 [00:02<00:13, 13.85it/s] 11%|█▏        | 23/204 [00:02<00:14, 12.08it/s] 12%|█▏        | 25/204 [00:02<00:18,  9.79it/s] 13%|█▎        | 27/204 [00:03<00:20,  8.75it/s] 14%|█▎        | 28/204 [00:03<00:20,  8.63it/s] 14%|█▍        | 29/204 [00:03<00:20,  8.48it/s] 15%|█▍        | 30/204 [00:03<00:21,  8.16it/s] 15%|█▌        | 31/204 [00:03<00:22,  7.85it/s] 16%|█▌        | 32/204 [00:03<00:22,  7.72it/s] 16%|█▌        | 33/204 [00:03<00:22,  7.71it/s] 17%|█▋        | 34/204 [00:03<00:21,  7.79it/s] 17%|█▋        | 35/204 [00:04<00:21,  7.92it/s] 18%|█▊        | 36/204 [00:04<00:21,  7.97it/s] 19%|█▊        | 38/204 [00:04<00:17,  9.35it/s] 20%|█▉        | 40/204 [00:04<00:14, 10.94it/s] 21%|██        | 42/204 [00:04<00:13, 12.06it/s] 22%|██▏       | 44/204 [00:04<00:12, 12.84it/s] 23%|██▎       | 46/204 [00:04<00:11, 13.49it/s] 24%|██▎       | 48/204 [00:05<00:11, 13.73it/s] 25%|██▍       | 50/204 [00:05<00:14, 10.79it/s] 25%|██▌       | 52/204 [00:05<00:17,  8.93it/s] 26%|██▋       | 54/204 [00:05<00:17,  8.51it/s] 27%|██▋       | 55/204 [00:06<00:17,  8.41it/s] 27%|██▋       | 56/204 [00:06<00:18,  8.07it/s] 28%|██▊       | 57/204 [00:06<00:18,  7.82it/s] 28%|██▊       | 58/204 [00:06<00:19,  7.65it/s] 29%|██▉       | 59/204 [00:06<00:18,  7.73it/s] 29%|██▉       | 60/204 [00:06<00:18,  7.79it/s] 30%|██▉       | 61/204 [00:06<00:18,  7.85it/s] 30%|███       | 62/204 [00:06<00:18,  7.85it/s] 31%|███▏      | 64/204 [00:07<00:14,  9.51it/s] 32%|███▏      | 66/204 [00:07<00:12, 10.96it/s] 33%|███▎      | 68/204 [00:07<00:11, 11.99it/s] 34%|███▍      | 70/204 [00:07<00:10, 12.79it/s] 35%|███▌      | 72/204 [00:07<00:09, 13.38it/s] 36%|███▋      | 74/204 [00:07<00:09, 13.84it/s] 37%|███▋      | 76/204 [00:07<00:09, 14.05it/s] 38%|███▊      | 78/204 [00:08<00:08, 14.19it/s] 39%|███▉      | 80/204 [00:08<00:08, 14.19it/s] 40%|████      | 82/204 [00:08<00:08, 14.27it/s] 41%|████      | 84/204 [00:08<00:08, 14.18it/s] 42%|████▏     | 86/204 [00:08<00:08, 14.26it/s] 43%|████▎     | 88/204 [00:08<00:08, 14.22it/s] 44%|████▍     | 90/204 [00:08<00:08, 14.22it/s] 45%|████▌     | 92/204 [00:09<00:07, 14.25it/s] 46%|████▌     | 94/204 [00:09<00:07, 14.06it/s] 47%|████▋     | 96/204 [00:09<00:07, 14.10it/s] 48%|████▊     | 98/204 [00:09<00:07, 14.04it/s] 49%|████▉     | 100/204 [00:09<00:07, 14.24it/s] 50%|█████     | 102/204 [00:09<00:07, 14.25it/s] 51%|█████     | 104/204 [00:09<00:06, 14.36it/s] 52%|█████▏    | 106/204 [00:10<00:06, 14.45it/s] 53%|█████▎    | 108/204 [00:10<00:06, 14.49it/s] 54%|█████▍    | 110/204 [00:10<00:06, 14.47it/s] 55%|█████▍    | 112/204 [00:10<00:06, 14.52it/s] 56%|█████▌    | 114/204 [00:10<00:06, 14.50it/s] 57%|█████▋    | 116/204 [00:10<00:06, 14.46it/s] 58%|█████▊    | 118/204 [00:10<00:06, 14.28it/s] 59%|█████▉    | 120/204 [00:11<00:05, 14.26it/s] 60%|█████▉    | 122/204 [00:11<00:05, 14.17it/s] 61%|██████    | 124/204 [00:11<00:05, 14.19it/s] 62%|██████▏   | 126/204 [00:11<00:05, 14.14it/s] 63%|██████▎   | 128/204 [00:11<00:05, 14.18it/s] 64%|██████▎   | 130/204 [00:11<00:05, 14.19it/s] 65%|██████▍   | 132/204 [00:11<00:05, 14.28it/s] 66%|██████▌   | 134/204 [00:11<00:04, 14.28it/s] 67%|██████▋   | 136/204 [00:12<00:04, 14.12it/s] 68%|██████▊   | 138/204 [00:12<00:04, 14.22it/s] 69%|██████▊   | 140/204 [00:12<00:04, 14.11it/s] 70%|██████▉   | 142/204 [00:12<00:04, 14.28it/s] 71%|███████   | 144/204 [00:12<00:04, 14.27it/s] 72%|███████▏  | 146/204 [00:12<00:04, 14.30it/s] 73%|███████▎  | 148/204 [00:12<00:03, 14.22it/s] 74%|███████▎  | 150/204 [00:13<00:03, 14.23it/s] 75%|███████▍  | 152/204 [00:13<00:03, 14.31it/s] 75%|███████▌  | 154/204 [00:13<00:03, 14.34it/s] 76%|███████▋  | 156/204 [00:13<00:03, 14.25it/s] 77%|███████▋  | 158/204 [00:13<00:03, 13.98it/s] 78%|███████▊  | 160/204 [00:13<00:03, 13.73it/s] 79%|███████▉  | 162/204 [00:13<00:03, 13.84it/s] 80%|████████  | 164/204 [00:14<00:02, 13.85it/s] 81%|████████▏ | 166/204 [00:14<00:02, 13.87it/s] 82%|████████▏ | 168/204 [00:14<00:02, 13.99it/s] 83%|████████▎ | 170/204 [00:14<00:02, 13.84it/s] 84%|████████▍ | 172/204 [00:14<00:02, 13.93it/s] 85%|████████▌ | 174/204 [00:14<00:02, 13.90it/s] 86%|████████▋ | 176/204 [00:14<00:01, 14.10it/s] 87%|████████▋ | 178/204 [00:15<00:01, 14.07it/s] 88%|████████▊ | 180/204 [00:15<00:01, 14.11it/s] 89%|████████▉ | 182/204 [00:15<00:01, 14.16it/s] 90%|█████████ | 184/204 [00:15<00:01, 14.34it/s] 91%|█████████ | 186/204 [00:15<00:01, 14.17it/s] 92%|█████████▏| 188/204 [00:15<00:01, 14.34it/s] 93%|█████████▎| 190/204 [00:15<00:00, 14.30it/s] 94%|█████████▍| 192/204 [00:16<00:00, 14.22it/s] 95%|█████████▌| 194/204 [00:16<00:00, 14.21it/s] 96%|█████████▌| 196/204 [00:16<00:00, 14.41it/s] 97%|█████████▋| 198/204 [00:16<00:00, 14.47it/s] 98%|█████████▊| 200/204 [00:16<00:00, 14.56it/s] 99%|█████████▉| 202/204 [00:16<00:00, 14.35it/s]100%|██████████| 204/204 [00:17<00:00, 11.99it/s]
2025-01-25 15:15:04,244 - INFO - Results for 'SVHN': {'top1': 0.9048478795328826}
2025-01-25 15:15:04,245 - INFO - Evaluation results saved to mties_log/vit_b32.json
2025-01-25 15:15:04,245 - INFO - m_TIES script completed successfully.
Done evaluating on SVHN. Accuracy: 90.48%
/scratch/wangtiantong/miniconda3/envs/task-vectors/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
2025-01-25 15:19:55,219 - INFO - Starting m_TIES script.
2025-01-25 15:19:55,220 - INFO - Building an unlabeled combined DataLoader.
2025-01-25 15:19:55,220 - INFO - Loading dataset 'MNIST' for unlabeled sampling.
2025-01-25 15:19:55,288 - INFO - Dataset 'MNIST': Chosen 500 samples out of 60000.
2025-01-25 15:19:55,288 - INFO - Loading dataset 'DTD' for unlabeled sampling.
2025-01-25 15:19:55,298 - INFO - Dataset 'DTD': Chosen 18 samples out of 1880.
2025-01-25 15:19:55,298 - INFO - Loading dataset 'EuroSAT' for unlabeled sampling.
2025-01-25 15:19:55,337 - INFO - Dataset 'EuroSAT': Chosen 216 samples out of 21600.
2025-01-25 15:19:55,337 - INFO - Loading dataset 'GTSRB' for unlabeled sampling.
2025-01-25 15:19:55,422 - INFO - Dataset 'GTSRB': Chosen 266 samples out of 26640.
2025-01-25 15:19:55,422 - INFO - Loading dataset 'SUN397' for unlabeled sampling.
2025-01-25 15:19:56,121 - INFO - Dataset 'SUN397': Chosen 500 samples out of 87003.
2025-01-25 15:19:56,121 - INFO - Loading dataset 'SVHN' for unlabeled sampling.
2025-01-25 15:19:58,906 - INFO - Dataset 'SVHN': Chosen 500 samples out of 73257.
2025-01-25 15:19:58,906 - INFO - Total combined unlabeled samples: 2000
2025-01-25 15:19:58,906 - INFO - Unlabeled DataLoader created successfully.
2025-01-25 15:19:58,908 - INFO - Unlabeled data loader built successfully.
2025-01-25 15:19:58,909 - INFO - Starting m_TIES merging process.
2025-01-25 15:19:58,909 - INFO - Base keep ratio k=0.2, vibration coefficient e=0.19.
2025-01-25 15:19:58,909 - INFO - Loading pretrained model from 'checkpoints/ViT-B-32/zeroshot.pt'
/scratch/wangtiantong/task_vectors/m_ties.py:118: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  pretrained_model = torch.load(pretrained_checkpoint, map_location='cpu')
2025-01-25 15:19:59,169 - INFO - Loading finetuned checkpoint 'checkpoints/ViT-B-32/MNIST/finetuned.pt'
/scratch/wangtiantong/task_vectors/src/task_vectors.py:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  pretrained_state_dict = torch.load(pretrained_checkpoint).state_dict()
/scratch/wangtiantong/task_vectors/src/task_vectors.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  finetuned_state_dict = torch.load(finetuned_checkpoint).state_dict()
2025-01-25 15:19:59,727 - INFO - Loading finetuned checkpoint 'checkpoints/ViT-B-32/DTD/finetuned.pt'
2025-01-25 15:20:00,199 - INFO - Loading finetuned checkpoint 'checkpoints/ViT-B-32/EuroSAT/finetuned.pt'
2025-01-25 15:20:00,525 - INFO - Loading finetuned checkpoint 'checkpoints/ViT-B-32/GTSRB/finetuned.pt'
2025-01-25 15:20:00,819 - INFO - Loading finetuned checkpoint 'checkpoints/ViT-B-32/SUN397/finetuned.pt'
2025-01-25 15:20:01,109 - INFO - Loading finetuned checkpoint 'checkpoints/ViT-B-32/SVHN/finetuned.pt'
2025-01-25 15:20:12,481 - INFO - m_TIES merging process completed.
/scratch/wangtiantong/task_vectors/src/task_vectors.py:58: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  pretrained_model = torch.load(pretrained_checkpoint)
2025-01-25 15:20:12,997 - INFO - Merged model constructed successfully.
2025-01-25 15:20:12,997 - INFO - Evaluating merged model on each dataset.
2025-01-25 15:20:12,997 - INFO - Evaluating dataset 'MNIST'.
/scratch/wangtiantong/task_vectors/src/utils.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model = torch.load(save_path)
Using downloaded and verified file: datasets/svhn/train_32x32.mat
Using downloaded and verified file: datasets/svhn/test_32x32.mat
Classification head for ViT-B-32 on MNIST exists at checkpoints/ViT-B-32/head_MNIST.pt
Loading classification head from checkpoints/ViT-B-32/head_MNIST.pt
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:01<01:49,  1.41s/it]  4%|▍         | 3/79 [00:01<00:31,  2.39it/s]  6%|▋         | 5/79 [00:01<00:17,  4.16it/s]  9%|▉         | 7/79 [00:01<00:12,  5.95it/s] 11%|█▏        | 9/79 [00:01<00:09,  7.61it/s] 14%|█▍        | 11/79 [00:02<00:07,  9.10it/s] 16%|█▋        | 13/79 [00:02<00:06,  9.94it/s] 19%|█▉        | 15/79 [00:02<00:05, 11.12it/s] 22%|██▏       | 17/79 [00:02<00:05, 11.75it/s] 24%|██▍       | 19/79 [00:02<00:04, 12.59it/s] 27%|██▋       | 21/79 [00:02<00:04, 13.29it/s] 29%|██▉       | 23/79 [00:02<00:04, 13.96it/s] 32%|███▏      | 25/79 [00:03<00:03, 14.41it/s] 34%|███▍      | 27/79 [00:03<00:03, 14.67it/s] 37%|███▋      | 29/79 [00:03<00:03, 14.82it/s] 39%|███▉      | 31/79 [00:03<00:03, 12.81it/s] 42%|████▏     | 33/79 [00:03<00:03, 13.07it/s] 44%|████▍     | 35/79 [00:03<00:03, 13.55it/s] 47%|████▋     | 37/79 [00:03<00:02, 14.03it/s] 49%|████▉     | 39/79 [00:04<00:02, 14.41it/s] 52%|█████▏    | 41/79 [00:04<00:02, 13.36it/s] 54%|█████▍    | 43/79 [00:04<00:02, 13.75it/s] 57%|█████▋    | 45/79 [00:04<00:02, 13.64it/s] 59%|█████▉    | 47/79 [00:04<00:02, 13.81it/s] 62%|██████▏   | 49/79 [00:04<00:02, 14.06it/s] 65%|██████▍   | 51/79 [00:04<00:01, 14.44it/s] 67%|██████▋   | 53/79 [00:05<00:01, 13.42it/s] 70%|██████▉   | 55/79 [00:05<00:01, 13.94it/s] 72%|███████▏  | 57/79 [00:05<00:01, 14.34it/s] 75%|███████▍  | 59/79 [00:05<00:01, 14.55it/s] 77%|███████▋  | 61/79 [00:05<00:01, 14.46it/s] 80%|███████▉  | 63/79 [00:05<00:01, 13.00it/s] 82%|████████▏ | 65/79 [00:06<00:01, 13.11it/s] 85%|████████▍ | 67/79 [00:06<00:00, 13.25it/s] 87%|████████▋ | 69/79 [00:06<00:00, 13.54it/s] 90%|████████▉ | 71/79 [00:06<00:00, 13.69it/s] 92%|█████████▏| 73/79 [00:06<00:00, 13.21it/s] 95%|█████████▍| 75/79 [00:06<00:00, 13.23it/s] 97%|█████████▋| 77/79 [00:06<00:00, 13.45it/s]100%|██████████| 79/79 [00:07<00:00, 14.58it/s]100%|██████████| 79/79 [00:07<00:00, 11.12it/s]
2025-01-25 15:20:20,157 - INFO - Results for 'MNIST': {'top1': 0.9882}
2025-01-25 15:20:20,157 - INFO - Evaluating dataset 'DTD'.
Done evaluating on MNIST. Accuracy: 98.82%
Classification head for ViT-B-32 on DTD exists at checkpoints/ViT-B-32/head_DTD.pt
Loading classification head from checkpoints/ViT-B-32/head_DTD.pt
  0%|          | 0/15 [00:00<?, ?it/s]  7%|▋         | 1/15 [00:01<00:20,  1.45s/it] 20%|██        | 3/15 [00:01<00:05,  2.36it/s] 33%|███▎      | 5/15 [00:01<00:02,  4.19it/s] 47%|████▋     | 7/15 [00:01<00:01,  6.04it/s] 60%|██████    | 9/15 [00:01<00:00,  7.82it/s] 73%|███████▎  | 11/15 [00:02<00:00,  8.85it/s] 87%|████████▋ | 13/15 [00:02<00:00, 10.22it/s]100%|██████████| 15/15 [00:02<00:00, 11.92it/s]100%|██████████| 15/15 [00:02<00:00,  5.92it/s]
2025-01-25 15:20:22,712 - INFO - Results for 'DTD': {'top1': 0.5792553191489361}
2025-01-25 15:20:22,712 - INFO - Evaluating dataset 'EuroSAT'.
Done evaluating on DTD. Accuracy: 57.93%
Classification head for ViT-B-32 on EuroSAT exists at checkpoints/ViT-B-32/head_EuroSAT.pt
Loading classification head from checkpoints/ViT-B-32/head_EuroSAT.pt
  0%|          | 0/43 [00:00<?, ?it/s]  2%|▏         | 1/43 [00:00<00:35,  1.18it/s]  5%|▍         | 2/43 [00:00<00:17,  2.34it/s]  9%|▉         | 4/43 [00:01<00:07,  4.92it/s] 14%|█▍        | 6/43 [00:01<00:05,  6.75it/s] 19%|█▊        | 8/43 [00:01<00:04,  8.54it/s] 23%|██▎       | 10/43 [00:01<00:03,  9.96it/s] 28%|██▊       | 12/43 [00:01<00:02, 11.07it/s] 33%|███▎      | 14/43 [00:01<00:02, 11.70it/s] 37%|███▋      | 16/43 [00:02<00:02, 11.93it/s] 42%|████▏     | 18/43 [00:02<00:02, 11.67it/s] 47%|████▋     | 20/43 [00:02<00:01, 12.32it/s] 51%|█████     | 22/43 [00:02<00:01, 12.80it/s] 56%|█████▌    | 24/43 [00:02<00:01, 13.09it/s] 60%|██████    | 26/43 [00:02<00:01, 13.36it/s] 65%|██████▌   | 28/43 [00:02<00:01, 12.70it/s] 70%|██████▉   | 30/43 [00:03<00:00, 13.12it/s] 74%|███████▍  | 32/43 [00:03<00:00, 13.18it/s] 79%|███████▉  | 34/43 [00:03<00:00, 13.39it/s] 84%|████████▎ | 36/43 [00:03<00:00, 13.52it/s] 88%|████████▊ | 38/43 [00:03<00:00, 12.37it/s] 93%|█████████▎| 40/43 [00:03<00:00, 12.73it/s] 98%|█████████▊| 42/43 [00:04<00:00, 12.78it/s]100%|██████████| 43/43 [00:04<00:00, 10.36it/s]
2025-01-25 15:20:26,922 - INFO - Results for 'EuroSAT': {'top1': 0.7605555555555555}
2025-01-25 15:20:26,922 - INFO - Evaluating dataset 'GTSRB'.
Done evaluating on EuroSAT. Accuracy: 76.06%
Classification head for ViT-B-32 on GTSRB exists at checkpoints/ViT-B-32/head_GTSRB.pt
Loading classification head from checkpoints/ViT-B-32/head_GTSRB.pt
  0%|          | 0/99 [00:00<?, ?it/s]  1%|          | 1/99 [00:00<01:25,  1.14it/s]  3%|▎         | 3/99 [00:01<00:26,  3.60it/s]  5%|▌         | 5/99 [00:01<00:16,  5.53it/s]  7%|▋         | 7/99 [00:01<00:12,  7.58it/s]  9%|▉         | 9/99 [00:01<00:09,  9.18it/s] 11%|█         | 11/99 [00:01<00:08, 10.61it/s] 13%|█▎        | 13/99 [00:01<00:07, 11.83it/s] 15%|█▌        | 15/99 [00:01<00:06, 12.70it/s] 17%|█▋        | 17/99 [00:02<00:06, 12.47it/s] 19%|█▉        | 19/99 [00:02<00:06, 13.17it/s] 21%|██        | 21/99 [00:02<00:05, 13.56it/s] 23%|██▎       | 23/99 [00:02<00:05, 14.09it/s] 25%|██▌       | 25/99 [00:02<00:05, 14.07it/s] 27%|██▋       | 27/99 [00:02<00:05, 14.37it/s] 29%|██▉       | 29/99 [00:02<00:05, 13.28it/s] 31%|███▏      | 31/99 [00:03<00:04, 13.87it/s] 33%|███▎      | 33/99 [00:03<00:04, 14.18it/s] 35%|███▌      | 35/99 [00:03<00:04, 14.41it/s] 37%|███▋      | 37/99 [00:03<00:04, 14.49it/s] 39%|███▉      | 39/99 [00:03<00:04, 13.65it/s] 41%|████▏     | 41/99 [00:03<00:04, 13.79it/s] 43%|████▎     | 43/99 [00:03<00:04, 13.86it/s] 45%|████▌     | 45/99 [00:04<00:03, 13.85it/s] 47%|████▋     | 47/99 [00:04<00:03, 14.02it/s] 49%|████▉     | 49/99 [00:04<00:03, 14.25it/s] 52%|█████▏    | 51/99 [00:04<00:03, 13.40it/s] 54%|█████▎    | 53/99 [00:04<00:03, 13.83it/s] 56%|█████▌    | 55/99 [00:04<00:03, 14.09it/s] 58%|█████▊    | 57/99 [00:04<00:02, 14.27it/s] 60%|█████▉    | 59/99 [00:04<00:02, 14.31it/s] 62%|██████▏   | 61/99 [00:05<00:02, 14.51it/s] 64%|██████▎   | 63/99 [00:05<00:02, 14.62it/s] 66%|██████▌   | 65/99 [00:05<00:02, 14.71it/s] 68%|██████▊   | 67/99 [00:05<00:02, 14.75it/s] 70%|██████▉   | 69/99 [00:05<00:02, 14.88it/s] 72%|███████▏  | 71/99 [00:05<00:01, 14.83it/s] 74%|███████▎  | 73/99 [00:05<00:01, 14.68it/s] 76%|███████▌  | 75/99 [00:06<00:01, 14.71it/s] 78%|███████▊  | 77/99 [00:06<00:01, 14.74it/s] 80%|███████▉  | 79/99 [00:06<00:01, 14.77it/s] 82%|████████▏ | 81/99 [00:06<00:01, 12.74it/s] 84%|████████▍ | 83/99 [00:06<00:01, 13.32it/s] 86%|████████▌ | 85/99 [00:06<00:01, 13.74it/s] 88%|████████▊ | 87/99 [00:06<00:00, 13.99it/s] 90%|████████▉ | 89/99 [00:07<00:00, 14.06it/s] 92%|█████████▏| 91/99 [00:07<00:00, 14.21it/s] 94%|█████████▍| 93/99 [00:07<00:00, 13.35it/s] 96%|█████████▌| 95/99 [00:07<00:00, 13.78it/s] 98%|█████████▊| 97/99 [00:07<00:00, 13.98it/s]100%|██████████| 99/99 [00:07<00:00, 14.96it/s]100%|██████████| 99/99 [00:07<00:00, 12.53it/s]
2025-01-25 15:20:34,907 - INFO - Results for 'GTSRB': {'top1': 0.7705463182897863}
2025-01-25 15:20:34,907 - INFO - Evaluating dataset 'SUN397'.
Done evaluating on GTSRB. Accuracy: 77.05%
Classification head for ViT-B-32 on SUN397 exists at checkpoints/ViT-B-32/head_SUN397.pt
Loading classification head from checkpoints/ViT-B-32/head_SUN397.pt
  0%|          | 0/170 [00:00<?, ?it/s]  1%|          | 1/170 [00:02<06:48,  2.42s/it]  1%|          | 2/170 [00:02<03:29,  1.25s/it]  2%|▏         | 4/170 [00:03<01:25,  1.94it/s]  4%|▎         | 6/170 [00:03<00:51,  3.18it/s]  5%|▍         | 8/170 [00:03<00:34,  4.64it/s]  6%|▌         | 10/170 [00:03<00:26,  6.15it/s]  7%|▋         | 12/170 [00:03<00:21,  7.36it/s]  8%|▊         | 14/170 [00:03<00:17,  8.87it/s]  9%|▉         | 16/170 [00:03<00:15, 10.17it/s] 11%|█         | 18/170 [00:04<00:27,  5.49it/s] 12%|█▏        | 20/170 [00:05<00:33,  4.47it/s] 13%|█▎        | 22/170 [00:05<00:26,  5.67it/s] 14%|█▍        | 24/170 [00:05<00:20,  6.99it/s] 15%|█▌        | 26/170 [00:05<00:21,  6.68it/s] 16%|█▌        | 27/170 [00:07<01:03,  2.26it/s] 17%|█▋        | 29/170 [00:07<00:44,  3.16it/s] 18%|█▊        | 31/170 [00:07<00:33,  4.21it/s] 19%|█▉        | 33/170 [00:08<00:25,  5.36it/s] 21%|██        | 35/170 [00:08<00:20,  6.52it/s] 22%|██▏       | 37/170 [00:08<00:17,  7.48it/s] 23%|██▎       | 39/170 [00:08<00:15,  8.46it/s] 24%|██▍       | 41/170 [00:08<00:14,  9.18it/s] 25%|██▌       | 43/170 [00:10<00:49,  2.59it/s] 26%|██▋       | 45/170 [00:10<00:36,  3.43it/s] 28%|██▊       | 47/170 [00:11<00:27,  4.45it/s] 29%|██▉       | 49/170 [00:11<00:21,  5.61it/s] 30%|███       | 51/170 [00:11<00:17,  6.92it/s] 31%|███       | 53/170 [00:11<00:14,  8.25it/s] 32%|███▏      | 55/170 [00:11<00:12,  9.45it/s] 34%|███▎      | 57/170 [00:11<00:10, 10.31it/s] 35%|███▍      | 59/170 [00:13<00:34,  3.26it/s] 36%|███▌      | 61/170 [00:13<00:26,  4.18it/s] 37%|███▋      | 63/170 [00:13<00:20,  5.25it/s] 38%|███▊      | 65/170 [00:13<00:16,  6.31it/s] 39%|███▉      | 67/170 [00:14<00:13,  7.49it/s] 41%|████      | 69/170 [00:14<00:11,  8.77it/s] 42%|████▏     | 71/170 [00:14<00:10,  9.87it/s] 43%|████▎     | 73/170 [00:14<00:08, 10.79it/s] 44%|████▍     | 75/170 [00:15<00:21,  4.36it/s] 45%|████▌     | 77/170 [00:15<00:16,  5.51it/s] 46%|████▋     | 79/170 [00:15<00:13,  6.77it/s] 48%|████▊     | 81/170 [00:15<00:11,  8.06it/s] 49%|████▉     | 83/170 [00:16<00:09,  9.27it/s] 50%|█████     | 85/170 [00:16<00:08, 10.44it/s] 51%|█████     | 87/170 [00:16<00:07, 11.44it/s] 52%|█████▏    | 89/170 [00:16<00:06, 11.97it/s] 54%|█████▎    | 91/170 [00:17<00:13,  5.89it/s] 55%|█████▍    | 93/170 [00:17<00:10,  7.12it/s] 56%|█████▌    | 95/170 [00:17<00:09,  8.23it/s] 57%|█████▋    | 97/170 [00:17<00:07,  9.23it/s] 58%|█████▊    | 99/170 [00:17<00:06, 10.38it/s] 59%|█████▉    | 101/170 [00:18<00:06, 11.40it/s] 61%|██████    | 103/170 [00:18<00:05, 12.24it/s] 62%|██████▏   | 105/170 [00:18<00:05, 12.69it/s] 63%|██████▎   | 107/170 [00:19<00:14,  4.28it/s] 64%|██████▍   | 109/170 [00:19<00:11,  5.39it/s] 65%|██████▌   | 111/170 [00:19<00:08,  6.64it/s] 66%|██████▋   | 113/170 [00:19<00:07,  7.79it/s] 68%|██████▊   | 115/170 [00:20<00:06,  8.92it/s] 69%|██████▉   | 117/170 [00:20<00:05,  9.81it/s] 70%|███████   | 119/170 [00:20<00:04, 10.80it/s] 71%|███████   | 121/170 [00:20<00:04, 11.61it/s] 72%|███████▏  | 123/170 [00:21<00:07,  6.10it/s] 74%|███████▎  | 125/170 [00:21<00:06,  7.26it/s] 75%|███████▍  | 127/170 [00:22<00:13,  3.20it/s] 76%|███████▌  | 129/170 [00:22<00:09,  4.18it/s] 77%|███████▋  | 131/170 [00:23<00:07,  5.32it/s] 78%|███████▊  | 133/170 [00:23<00:05,  6.57it/s] 79%|███████▉  | 135/170 [00:23<00:04,  7.87it/s] 81%|████████  | 137/170 [00:23<00:03,  9.12it/s] 82%|████████▏ | 139/170 [00:23<00:03, 10.08it/s] 83%|████████▎ | 141/170 [00:23<00:02, 10.70it/s] 84%|████████▍ | 143/170 [00:24<00:03,  7.30it/s] 85%|████████▌ | 145/170 [00:24<00:02,  8.51it/s] 86%|████████▋ | 147/170 [00:24<00:02,  9.75it/s] 88%|████████▊ | 149/170 [00:24<00:01, 10.81it/s] 89%|████████▉ | 151/170 [00:24<00:01, 11.77it/s] 90%|█████████ | 153/170 [00:24<00:01, 12.42it/s] 91%|█████████ | 155/170 [00:25<00:01, 12.71it/s] 92%|█████████▏| 157/170 [00:25<00:02,  5.44it/s] 94%|█████████▎| 159/170 [00:26<00:02,  4.72it/s] 95%|█████████▍| 161/170 [00:26<00:01,  5.91it/s] 96%|█████████▌| 163/170 [00:26<00:00,  7.19it/s] 97%|█████████▋| 165/170 [00:26<00:00,  8.45it/s] 98%|█████████▊| 167/170 [00:27<00:00,  9.75it/s] 99%|█████████▉| 169/170 [00:27<00:00, 10.84it/s]100%|██████████| 170/170 [00:27<00:00,  6.20it/s]
2025-01-25 15:21:03,028 - INFO - Results for 'SUN397': {'top1': 0.6157877798721898}
2025-01-25 15:21:03,029 - INFO - Evaluating dataset 'SVHN'.
Done evaluating on SUN397. Accuracy: 61.58%
Classification head for ViT-B-32 on SVHN exists at checkpoints/ViT-B-32/head_SVHN.pt
Loading classification head from checkpoints/ViT-B-32/head_SVHN.pt
Using downloaded and verified file: datasets/svhn/train_32x32.mat
Using downloaded and verified file: datasets/svhn/test_32x32.mat
  0%|          | 0/204 [00:00<?, ?it/s]  0%|          | 1/204 [00:01<03:42,  1.10s/it]  1%|▏         | 3/204 [00:01<01:08,  2.94it/s]  2%|▏         | 5/204 [00:01<00:39,  4.99it/s]  3%|▎         | 7/204 [00:01<00:28,  6.90it/s]  4%|▍         | 9/204 [00:01<00:22,  8.65it/s]  5%|▌         | 11/204 [00:01<00:19, 10.11it/s]  6%|▋         | 13/204 [00:01<00:16, 11.39it/s]  7%|▋         | 15/204 [00:02<00:15, 12.40it/s]  8%|▊         | 17/204 [00:02<00:14, 12.86it/s]  9%|▉         | 19/204 [00:02<00:14, 12.93it/s] 10%|█         | 21/204 [00:02<00:13, 13.34it/s] 11%|█▏        | 23/204 [00:02<00:13, 13.53it/s] 12%|█▏        | 25/204 [00:02<00:13, 13.76it/s] 13%|█▎        | 27/204 [00:02<00:12, 13.94it/s] 14%|█▍        | 29/204 [00:03<00:12, 14.15it/s] 15%|█▌        | 31/204 [00:03<00:12, 14.23it/s] 16%|█▌        | 33/204 [00:03<00:11, 14.39it/s] 17%|█▋        | 35/204 [00:03<00:11, 14.25it/s] 18%|█▊        | 37/204 [00:03<00:11, 14.51it/s] 19%|█▉        | 39/204 [00:03<00:11, 14.43it/s] 20%|██        | 41/204 [00:03<00:11, 14.17it/s] 21%|██        | 43/204 [00:04<00:11, 14.03it/s] 22%|██▏       | 45/204 [00:04<00:11, 14.23it/s] 23%|██▎       | 47/204 [00:04<00:10, 14.41it/s] 24%|██▍       | 49/204 [00:04<00:10, 14.53it/s] 25%|██▌       | 51/204 [00:04<00:10, 14.10it/s] 26%|██▌       | 53/204 [00:04<00:10, 14.19it/s] 27%|██▋       | 55/204 [00:04<00:10, 14.09it/s] 28%|██▊       | 57/204 [00:05<00:10, 14.07it/s] 29%|██▉       | 59/204 [00:05<00:10, 13.99it/s] 30%|██▉       | 61/204 [00:05<00:10, 14.14it/s] 31%|███       | 63/204 [00:05<00:10, 14.08it/s] 32%|███▏      | 65/204 [00:05<00:09, 14.23it/s] 33%|███▎      | 67/204 [00:05<00:09, 14.02it/s] 34%|███▍      | 69/204 [00:05<00:09, 14.14it/s] 35%|███▍      | 71/204 [00:05<00:09, 14.37it/s] 36%|███▌      | 73/204 [00:06<00:09, 13.93it/s] 37%|███▋      | 75/204 [00:06<00:09, 14.04it/s] 38%|███▊      | 77/204 [00:06<00:08, 14.20it/s] 39%|███▊      | 79/204 [00:06<00:08, 14.16it/s] 40%|███▉      | 81/204 [00:06<00:08, 14.19it/s] 41%|████      | 83/204 [00:06<00:08, 14.08it/s] 42%|████▏     | 85/204 [00:07<00:08, 13.81it/s] 43%|████▎     | 87/204 [00:07<00:08, 13.74it/s] 44%|████▎     | 89/204 [00:07<00:08, 13.78it/s] 45%|████▍     | 91/204 [00:07<00:08, 13.86it/s] 46%|████▌     | 93/204 [00:07<00:07, 13.98it/s] 47%|████▋     | 95/204 [00:07<00:07, 14.19it/s] 48%|████▊     | 97/204 [00:07<00:07, 14.25it/s] 49%|████▊     | 99/204 [00:08<00:07, 14.07it/s] 50%|████▉     | 101/204 [00:08<00:07, 14.34it/s] 50%|█████     | 103/204 [00:08<00:07, 14.43it/s] 51%|█████▏    | 105/204 [00:08<00:06, 14.29it/s] 52%|█████▏    | 107/204 [00:08<00:06, 14.27it/s] 53%|█████▎    | 109/204 [00:08<00:06, 14.46it/s] 54%|█████▍    | 111/204 [00:08<00:06, 14.45it/s] 55%|█████▌    | 113/204 [00:08<00:06, 14.59it/s] 56%|█████▋    | 115/204 [00:09<00:06, 14.30it/s] 57%|█████▋    | 117/204 [00:09<00:06, 14.32it/s] 58%|█████▊    | 119/204 [00:09<00:05, 14.31it/s] 59%|█████▉    | 121/204 [00:09<00:05, 14.31it/s] 60%|██████    | 123/204 [00:09<00:05, 14.26it/s] 61%|██████▏   | 125/204 [00:09<00:05, 14.31it/s] 62%|██████▏   | 127/204 [00:09<00:05, 14.24it/s] 63%|██████▎   | 129/204 [00:10<00:05, 14.29it/s] 64%|██████▍   | 131/204 [00:10<00:05, 14.08it/s] 65%|██████▌   | 133/204 [00:10<00:04, 14.26it/s] 66%|██████▌   | 135/204 [00:10<00:04, 14.36it/s] 67%|██████▋   | 137/204 [00:10<00:04, 14.01it/s] 68%|██████▊   | 139/204 [00:10<00:04, 14.12it/s] 69%|██████▉   | 141/204 [00:10<00:04, 14.29it/s] 70%|███████   | 143/204 [00:11<00:04, 14.30it/s] 71%|███████   | 145/204 [00:11<00:04, 14.41it/s] 72%|███████▏  | 147/204 [00:11<00:04, 14.23it/s] 73%|███████▎  | 149/204 [00:11<00:03, 13.94it/s] 74%|███████▍  | 151/204 [00:11<00:03, 13.85it/s] 75%|███████▌  | 153/204 [00:11<00:03, 13.96it/s] 76%|███████▌  | 155/204 [00:11<00:03, 14.12it/s] 77%|███████▋  | 157/204 [00:12<00:03, 13.74it/s] 78%|███████▊  | 159/204 [00:12<00:03, 13.63it/s] 79%|███████▉  | 161/204 [00:12<00:03, 13.64it/s] 80%|███████▉  | 163/204 [00:12<00:02, 13.73it/s] 81%|████████  | 165/204 [00:12<00:02, 13.90it/s] 82%|████████▏ | 167/204 [00:12<00:02, 14.22it/s] 83%|████████▎ | 169/204 [00:12<00:02, 13.99it/s] 84%|████████▍ | 171/204 [00:13<00:02, 14.23it/s] 85%|████████▍ | 173/204 [00:13<00:02, 14.42it/s] 86%|████████▌ | 175/204 [00:13<00:01, 14.58it/s] 87%|████████▋ | 177/204 [00:13<00:02, 12.80it/s] 88%|████████▊ | 179/204 [00:13<00:02, 10.61it/s] 89%|████████▊ | 181/204 [00:14<00:02,  9.95it/s] 90%|████████▉ | 183/204 [00:14<00:02,  9.50it/s] 91%|█████████ | 185/204 [00:14<00:02,  9.21it/s] 91%|█████████ | 186/204 [00:14<00:01,  9.11it/s] 92%|█████████▏| 187/204 [00:14<00:01,  9.02it/s] 92%|█████████▏| 188/204 [00:14<00:01,  8.94it/s] 93%|█████████▎| 189/204 [00:14<00:01,  8.92it/s] 93%|█████████▎| 190/204 [00:15<00:01,  8.81it/s] 94%|█████████▎| 191/204 [00:15<00:01,  8.77it/s] 94%|█████████▍| 192/204 [00:15<00:01,  8.70it/s] 95%|█████████▍| 193/204 [00:15<00:01,  8.70it/s] 95%|█████████▌| 194/204 [00:15<00:01,  8.56it/s] 96%|█████████▌| 195/204 [00:15<00:01,  8.50it/s] 96%|█████████▌| 196/204 [00:15<00:00,  8.60it/s] 97%|█████████▋| 197/204 [00:15<00:00,  8.69it/s] 97%|█████████▋| 198/204 [00:16<00:00,  8.10it/s] 98%|█████████▊| 199/204 [00:16<00:00,  7.50it/s] 98%|█████████▊| 200/204 [00:16<00:00,  7.56it/s] 99%|█████████▊| 201/204 [00:16<00:00,  7.70it/s] 99%|█████████▉| 202/204 [00:16<00:00,  7.75it/s]100%|█████████▉| 203/204 [00:16<00:00,  7.56it/s]100%|██████████| 204/204 [00:16<00:00, 12.09it/s]
2025-01-25 15:21:22,543 - INFO - Results for 'SVHN': {'top1': 0.9048478795328826}
2025-01-25 15:21:22,543 - WARNING - Warning: No target layers were detected for row-wise trimming.
2025-01-25 15:21:22,543 - INFO - Evaluation results saved to mties_log/vit_b32.json
2025-01-25 15:21:22,543 - INFO - m_TIES script completed successfully.
Done evaluating on SVHN. Accuracy: 90.48%
